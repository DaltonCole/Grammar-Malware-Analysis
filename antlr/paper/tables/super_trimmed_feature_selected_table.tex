\begin{center}
\begin{table*}[htbp]
\caption{Extra Trimmed Features - Feature Selection}
\label{table:extra_trimmed_feature_selected}
\resizebox{\textwidth}{!}{%
\renewcommand{\arraystretch}{1.3}
\begin{tabular}{| c | c | c | c | c | c | c | c | c | c |}
\hline
N-Gram	& Algorithm	& Total Features	& True Positive \%	& False Positive \%	& True Negative \%	& False Negative \%	& Recall	& Precision	& $F_1$ \\
\hline \hline
2 	& 	Decision Tree 	& 	100 	& 	99.84 	& 	5.3533 	& 	94.6467 	& 	0.16 	& 	0.9984 	& 	0.9491 	& 	0.9731 		 \\
\hline
2 	& 	Random Forest 	& 	100 	& 	99.7733 	& 	5.0333 	& 	94.9667 	& 	0.2267 	& 	0.9977 	& 	0.952 	& 	0.9743 		 \\
\hline
2 	& 	Neural Network 	& 	100 	& 	97.3733 	& 	77.8733 	& 	22.1267 	& 	2.6267 	& 	0.9737 	& 	0.5556 	& 	0.7075 		 \\
\hline
2 	& 	Naive Bayes 	& 	100 	& 	95.4467 	& 	64.2133 	& 	35.7867 	& 	4.5533 	& 	0.9545 	& 	0.5978 	& 	0.7352 		 \\
\hline
2 	& 	Stochastic Gradient Descent Classifier 	& 	100 	& 	99.8933 	& 	6.0 	& 	94.0 	& 	0.1067 	& 	0.9989 	& 	0.9433 	& 	0.9703 		 \\
\hline
2 	& 	K-Nearest Neighbors 	& 	100 	& 	88.9133 	& 	1.0867 	& 	98.9133 	& 	11.0867 	& 	0.8891 	& 	0.9879 	& 	0.9359 		 \\
\hline
3 	& 	Decision Tree 	& 	100 	& 	99.8533 	& 	5.56 	& 	94.44 	& 	0.1467 	& 	0.9985 	& 	0.9473 	& 	0.9722 		 \\
\hline
3 	& 	Random Forest 	& 	100 	& 	99.68 	& 	5.24 	& 	94.76 	& 	0.32 	& 	0.9968 	& 	0.9501 	& 	0.9729 		 \\
\hline
3 	& 	Neural Network 	& 	100 	& 	84.26 	& 	35.4267 	& 	64.5733 	& 	15.74 	& 	0.8426 	& 	0.704 	& 	0.7671 		 \\
\hline
3 	& 	Naive Bayes 	& 	100 	& 	95.24 	& 	43.86 	& 	56.14 	& 	4.76 	& 	0.9524 	& 	0.6847 	& 	0.7967 		 \\
\hline
3 	& 	Stochastic Gradient Descent Classifier 	& 	100 	& 	99.9067 	& 	5.76 	& 	94.24 	& 	0.0933 	& 	0.9991 	& 	0.9455 	& 	0.9715 		 \\
\hline
3 	& 	K-Nearest Neighbors 	& 	100 	& 	90.3333 	& 	1.7533 	& 	98.2467 	& 	9.6667 	& 	0.9033 	& 	0.981 	& 	0.9405 		 \\
\hline
\end{tabular}}
\end{table*}
\end{center}
