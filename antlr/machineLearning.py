import argparse
import os
import io
import sys
import progressbar
from threading import Thread, Lock

class machineLearning:
	def __init__(self, parser_type):
		self.parser = parser_type()
		self.mutex = Lock()

	def feature_vector_setup(self, benign_directory: str, malicious_directory: str, file_extensions: list):
		benign_file_paths = []
		for root, dirs, files in os.walk(benign_directory):
			for file in files:
				for file_extension in file_extensions:
					if file.endswith(file_extension):
						benign_file_paths.append(os.path.join(root, file))

		malicious_file_paths = []
		for root, dirs, files in os.walk(malicious_directory):
			for file in files:
				for file_extension in file_extensions:
					if file.endswith(file_extension):
						malicious_file_paths.append(os.path.join(root, file))

		self.benign_feature_dictionaries = []
		self.malicious_feature_dictionaries = []

		# Holds parsing threads
		threads = []
		# Progress bar
		count = -1
		bar = self._progress_bar(len(benign_file_paths), "Benign File Parsing")
		# For each file
		for file in benign_file_paths:
			# Multi-thread parsing
			threads.append(Thread(target = self._find_feature_dictionary, \
				args = (file, self.benign_feature_dictionaries)))
			# Start thread
			threads[-1].start()
			# For every 16 threads, wait, so we don't start too many threads
			if len(threads) >= 16:
				# Join threads, update progress bar
				for thread in threads:
					thread.join()
					count += 1
					bar.update(count + 1)
				threads = []

		# Join threads, update progress bar
		for thread in threads:
			thread.join()
			count += 1
			bar.update(count + 1)			
		bar.finish()

		# Reset parsing threads
		threads = []
		# Progress bar
		count = -1
		bar = self._progress_bar(len(benign_file_paths), "Malicious File Parsing")
		# For each file
		for file in benign_file_paths:
			# Multi-thread parsing
			threads.append(Thread(target = self._find_feature_dictionary, \
				args = (file, self.malicious_feature_dictionaries)))
			# Start thread
			threads[-1].start()
			# For every 16 threads, wait, so we don't start too many threads
			if len(threads) >= 16:
				# Join threads, update progress bar
				for thread in threads:
					thread.join()
					count += 1
					bar.update(count + 1)
				threads = []

		# Join threads, update progress bar
		for thread in threads:
			thread.join()
			count += 1
			bar.update(count + 1)			
		bar.finish()


	def _progress_bar(self, size: int, name: str):
		print("Starting {}".format(name))
		bar = progressbar.ProgressBar(maxval = size, \
			widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])
		bar.start()

		return bar

	def _find_feature_dictionary(self, file: str, feature_dictionaries: list):
		# Redirect stdout and stderr
		sys.stdout = io.StringIO()
		sys.stderr = io.StringIO()

		rule_usage = self.parser.run_sample(file)

		# Restore stdout and stderr
		sys.stdout = sys.__stdout__
		sys.stderr = sys.__stderr__

		self.mutex.acquire()
		try:
			if rule_usage != None:
				feature_dictionaries.append(rule_usage)
		except:
			print("Append rule usage to feature_dictionaries FAILED")
		finally:
			self.mutex.release()


def main():
	from antlr_python3 import Python3ParserHandler

	ml = machineLearning(Python3ParserHandler)
	ml.feature_vector_setup("./samples/small_samples/", "./samples/small_samples/", [".py"])


if __name__ == '__main__':
    main()