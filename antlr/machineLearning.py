import argparse
import os
import io
import sys
import progressbar
from threading import Thread, Lock

class machineLearning:
	def __init__(self, parser_type):
		self.parser = parser_type()
		self.mutex = Lock()

	def feature_vector_setup(self, benign_directory: str, malicious_directory: str, file_extensions: list):
		"""Finds the feature dictionaries of each file in the benign and 
		malicious directories with the given file extensions

		Args:
			benign_directory (str): Directory containing the benign files
			malicious_directory (str): Directory containing the malicious files
			file_extensions ([str]): Acceptable file extensions

		Returns:
			Nothing. Sets two class instance variables
				self.benign_feature_dictionaries: [{"rule": count}]
				self.malicious_feature_dictionaries: [{"rule": count}]
		"""
		# Get benign code file paths
		benign_file_paths = []
		for root, dirs, files in os.walk(benign_directory):
			for file in files:
				for file_extension in file_extensions:
					if file.endswith(file_extension):
						benign_file_paths.append(os.path.join(root, file))

		# Get malicious code file paths
		malicious_file_paths = []
		for root, dirs, files in os.walk(malicious_directory):
			for file in files:
				for file_extension in file_extensions:
					if file.endswith(file_extension):
						malicious_file_paths.append(os.path.join(root, file))

		# Feature labeled dictionaries
		self.benign_feature_dictionaries = []
		self.malicious_feature_dictionaries = []

		# Holds parsing threads
		threads = []
		# Progress bar
		count = -1
		bar = self._progress_bar(len(benign_file_paths), "Benign File Parsing")
		# For each file
		for file in benign_file_paths:
			# Multi-thread parsing
			threads.append(Thread(target = self._find_feature_dictionary, \
				args = (file, self.benign_feature_dictionaries)))
			# Start thread
			threads[-1].start()
			# For every 16 threads, wait, so we don't start too many threads
			if len(threads) >= 16:
				# Join threads, update progress bar
				for thread in threads:
					thread.join()
					count += 1
					bar.update(count + 1)
				threads = []

		# Join threads, update progress bar
		for thread in threads:
			thread.join()
			count += 1
			bar.update(count + 1)			
		bar.finish()

		# Reset parsing threads
		threads = []
		# Progress bar
		count = -1
		bar = self._progress_bar(len(benign_file_paths), "Malicious File Parsing")
		# For each file
		for file in benign_file_paths:
			# Multi-thread parsing
			threads.append(Thread(target = self._find_feature_dictionary, \
				args = (file, self.malicious_feature_dictionaries)))
			# Start thread
			threads[-1].start()
			# For every 16 threads, wait, so we don't start too many threads
			if len(threads) >= 16:
				# Join threads, update progress bar
				for thread in threads:
					thread.join()
					count += 1
					bar.update(count + 1)
				threads = []

		# Join threads, update progress bar
		for thread in threads:
			thread.join()
			count += 1
			bar.update(count + 1)			
		bar.finish()


	def _progress_bar(self, size: int, name: str):
		"""Returns a progress bar
		Args:
			size (int): Max size of progress bar (i.e. 20/20)
			name (str): What the progress bar is for
		"""
		print("Starting {}".format(name))
		bar = progressbar.ProgressBar(maxval = size, \
			widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])
		bar.start()

		return bar

	def _find_feature_dictionary(self, file: str, feature_dictionaries: list):
		"""Find the feature dictionary of the specified file

		Supports multi-threading. Locks when adding features_dict to
		feature_dictionaries list.

		Uses self.mutex to lock resource.

		Args:
			file (str): File to parse and find the feature dictionary for
			feature_dictionaries ([{}]): List to add feature dictionary to

		Returns:
			Nothing. Appends features to feature_dictionaries list.
		"""
		# Get rules and rule usage
		rule_usage = self.parser.run_sample(file)

		self.mutex.acquire()
		try:
			if rule_usage != None:
				feature_dictionaries.append(rule_usage)
			else:
				pass
				#print("Failed file: {}".format(file))
		except:
			print("Append rule usage to feature_dictionaries FAILED")
		finally:
			self.mutex.release()


def main():
	from antlr_python3 import Python3ParserHandler

	ml = machineLearning(Python3ParserHandler)
	#ml.feature_vector_setup(".bad/", "//bad/", [".py"])
	ml.feature_vector_setup("./samples/Python-Programs/", "./samples/python-scripts/", [".py"])


if __name__ == '__main__':
    main()