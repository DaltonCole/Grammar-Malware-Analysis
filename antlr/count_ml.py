import argparse
import os
import io
import sys
from threading import Thread, Lock
import json
import queue
from copy import deepcopy
import numpy as np
from sklearn.model_selection import KFold
from sklearn.metrics import confusion_matrix
from statistics import mean
import progressbar
from math import factorial

"""
# NOTE ************************************************
# If number of times each grammar rule isn't useful, try percentage
# of how often the rule is used in the file (ie, normalize the data)

* Use tokens as a rule set as well
########################################################
"""

class MachineLearning:
	def __init__(self, show_progress_bar=True, save_file='./results.txt'):
		self.show_progress_bar = show_progress_bar
		self.feature_selection = False
		self.save_file = save_file

		self.feature_set = np.array(0)
		self.labels = np.array(0)

		self.benign_count = 0
		self.malicious_count = 0

		self.splits = 10 # k-split cross validation

		self.mutex = Lock()
		self.max_thread_count = 4
		self.queue = queue.Queue()

	def setup(self, benign_directory, malicious_directory, file_name='rule_order.json'):
		'''
		'''
		self.column_header_setup()
		self.feature_vector_setup(benign_directory, malicious_directory, file_name)

	def column_header_setup(self):
		self.columns = []

		self.columns.append('Program'.lower())
		self.columns.append('SourceElement'.lower())
		self.columns.append('Statement'.lower())
		self.columns.append('Block'.lower())
		self.columns.append('StatementList'.lower())
		self.columns.append('VariableStatement'.lower())
		self.columns.append('VariableDeclarationList'.lower())
		self.columns.append('VariableDeclaration'.lower())
		self.columns.append('EmptyStatement'.lower())
		self.columns.append('ExpressionStatement'.lower())
		self.columns.append('IfStatement'.lower())
		self.columns.append('DoStatement'.lower())
		self.columns.append('WhileStatement'.lower())
		self.columns.append('ForStatement'.lower())
		self.columns.append('ForVarStatement'.lower())
		self.columns.append('ForInStatement'.lower())
		self.columns.append('ForVarInStatement'.lower())
		self.columns.append('VarModifier'.lower())
		self.columns.append('ContinueStatement'.lower())
		self.columns.append('BreakStatement'.lower())
		self.columns.append('ReturnStatement'.lower())
		self.columns.append('WithStatement'.lower())
		self.columns.append('SwitchStatement'.lower())
		self.columns.append('CaseBlock'.lower())
		self.columns.append('CaseClauses'.lower())
		self.columns.append('CaseClause'.lower())
		self.columns.append('DefaultClause'.lower())
		self.columns.append('LabelledStatement'.lower())
		self.columns.append('ThrowStatement'.lower())
		self.columns.append('TryStatement'.lower())
		self.columns.append('CatchProduction'.lower())
		self.columns.append('FinallyProduction'.lower())
		self.columns.append('DebuggerStatement'.lower())
		self.columns.append('FunctionDeclaration'.lower())
		self.columns.append('ClassDeclaration'.lower())
		self.columns.append('ClassTail'.lower())
		self.columns.append('ClassElement'.lower())
		self.columns.append('MethodDefinition'.lower())
		self.columns.append('GeneratorMethod'.lower())
		self.columns.append('FormalParameterList'.lower())
		self.columns.append('FormalParameterArg'.lower())
		self.columns.append('LastFormalParameterArg'.lower())
		self.columns.append('FunctionBody'.lower())
		self.columns.append('SourceElements'.lower())
		self.columns.append('ArrayLiteral'.lower())
		self.columns.append('ElementList'.lower())
		self.columns.append('LastElement'.lower())
		self.columns.append('ObjectLiteral'.lower())
		self.columns.append('PropertyExpressionAssignment'.lower())
		self.columns.append('ComputedPropertyExpressionAssignment'.lower())
		self.columns.append('PropertyGetter'.lower())
		self.columns.append('PropertySetter'.lower())
		self.columns.append('MethodProperty'.lower())
		self.columns.append('PropertyShorthand'.lower())
		self.columns.append('PropertyName'.lower())
		self.columns.append('Arguments'.lower())
		self.columns.append('LastArgument'.lower())
		self.columns.append('ExpressionSequence'.lower())
		self.columns.append('TemplateStringExpression'.lower())
		self.columns.append('TernaryExpression'.lower())
		self.columns.append('LogicalAndExpression'.lower())
		self.columns.append('PreIncrementExpression'.lower())
		self.columns.append('ObjectLiteralExpression'.lower())
		self.columns.append('InExpression'.lower())
		self.columns.append('LogicalOrExpression'.lower())
		self.columns.append('NotExpression'.lower())
		self.columns.append('PreDecreaseExpression'.lower())
		self.columns.append('ArgumentsExpression'.lower())
		self.columns.append('ThisExpression'.lower())
		self.columns.append('FunctionExpression'.lower())
		self.columns.append('UnaryMinusExpression'.lower())
		self.columns.append('AssignmentExpression'.lower())
		self.columns.append('PostDecreaseExpression'.lower())
		self.columns.append('TypeofExpression'.lower())
		self.columns.append('InstanceofExpression'.lower())
		self.columns.append('UnaryPlusExpression'.lower())
		self.columns.append('DeleteExpression'.lower())
		self.columns.append('ArrowFunctionExpression'.lower())
		self.columns.append('EqualityExpression'.lower())
		self.columns.append('BitXOrExpression'.lower())
		self.columns.append('SuperExpression'.lower())
		self.columns.append('MultiplicativeExpression'.lower())
		self.columns.append('BitShiftExpression'.lower())
		self.columns.append('ParenthesizedExpression'.lower())
		self.columns.append('AdditiveExpression'.lower())
		self.columns.append('RelationalExpression'.lower())
		self.columns.append('PostIncrementExpression'.lower())
		self.columns.append('BitNotExpression'.lower())
		self.columns.append('NewExpression'.lower())
		self.columns.append('LiteralExpression'.lower())
		self.columns.append('ArrayLiteralExpression'.lower())
		self.columns.append('MemberDotExpression'.lower())
		self.columns.append('ClassExpression'.lower())
		self.columns.append('MemberIndexExpression'.lower())
		self.columns.append('IdentifierExpression'.lower())
		self.columns.append('BitAndExpression'.lower())
		self.columns.append('BitOrExpression'.lower())
		self.columns.append('AssignmentOperatorExpression'.lower())
		self.columns.append('VoidExpression'.lower())
		self.columns.append('ArrowFunctionParameters'.lower())
		self.columns.append('ArrowFunctionBody'.lower())
		self.columns.append('AssignmentOperator'.lower())
		self.columns.append('Literal'.lower())
		self.columns.append('NumericLiteral'.lower())
		self.columns.append('IdentifierName'.lower())
		self.columns.append('ReservedWord'.lower())
		self.columns.append('Keyword'.lower())
		self.columns.append('Getter'.lower())
		self.columns.append('Setter'.lower())
		self.columns.append('Eos'.lower())

		self.column_mapper = {}
		for index, col in enumerate(self.columns):
			self.column_mapper[col] = index

	def feature_selection_do(self):
		self.feature_selection = True

		# Perform feature selection
		from sklearn.feature_selection import VarianceThreshold

		sel = VarianceThreshold(threshold=(.8 * (1 - .8)))
		self.feature_set = sel.fit_transform(self.feature_set)

	def feature_vector_setup(self, benign_directory: str, malicious_directory: str, file_name='rule_order.json'):
		"""Finds the feature dictionaries of each file in the benign and 
		malicious directories with the given file extensions

		Args:
			benign_directory (str): Directory containing the benign files
			malicious_directory (str): Directory containing the malicious files
			file_name (str): Name of to use for feature

		Returns:
			Nothing. Populates class instance variables
				self.feature_set: [[]] List of list of features
				self.labels = [] Labels for each list of features in feature_set
		"""
		# Get benign code file paths
		benign_file_paths = []
		for root, dirs, files in os.walk(benign_directory):
			for file in files:
				if file == file_name:
					benign_file_paths.append(os.path.join(root, file))

		# Get malicious code file paths
		malicious_file_paths = []
		for root, dirs, files in os.walk(malicious_directory):
			for file in files:
				if file == file_name:
					malicious_file_paths.append(os.path.join(root, file))

		self.feature_set = np.empty((len(benign_file_paths) + len(malicious_file_paths),
			len(self.column_mapper)), int)

		with progressbar.ProgressBar(max_value=len(benign_file_paths) + len(malicious_file_paths)) as bar:
			self.count = 0
			if self.show_progress_bar:
				bar.update(0)

			threads = []
			for i in range(self.max_thread_count):
				t = Thread(target=self._feature_set_mapper_queue)
				t.start()
				threads.append(t)

			# For each file
			for row, file_path in enumerate(benign_file_paths + malicious_file_paths):
				item = {'file': file_path, 'row': row, 'bar': bar}
				# Add to threading queue
				self.queue.put(item)

			# Wait until all tasks are finished
			self.queue.join()

			# Stop threads
			for i in range(self.max_thread_count):
				self.queue.put(None)
			for t in threads:
				t.join()

		# Add labels (benign = 0, malicious = 1)
		self.labels = np.zeros(len(benign_file_paths) + len(malicious_file_paths))
		for i in range(len(benign_file_paths), self.labels.size):
			self.labels[i] = 1
		###################################

	def _feature_set_mapper_queue(self):
		while True:
			arguments = self.queue.get()
			if arguments is None:
				break

			file_path = arguments['file']
			row = arguments['row']
			bar = arguments['bar']
			data = None

			with open(file_path, 'r') as file:
				data = json.load(file)

			self.mutex.acquire()
			try:
				for key, value in data.items():
					col = self.column_mapper[key.lower()]

					self.feature_set[row, col] = value

				self.count += 1
				if self.show_progress_bar:
					bar.update(self.count)
			finally:
				self.mutex.release()

			self.queue.task_done()


	def pickle_it(self, directory, save_file):
		import pickle
		if not os.path.exists(directory):
			os.makedirs(directory)

		path = directory + '/' + save_file + '__'

		pickle.dump(self.feature_set, open(path + "feature_set.p", "wb"))
		pickle.dump(self.labels, open(path + "feature_labels.p", "wb"))
		print("Pickled Success!")

	def unpickle_it(self, directory):
		import pickle
		self.feature_set = pickle.load(open(directory + "/feature_set.p", "rb"))
		self.labels = pickle.load(open(directory + "/feature_labels.p", "rb"))

	def _cross_val_score_queue(self):
		while True:
			arguments = self.queue.get()
			if arguments is None:
				break
			clf = deepcopy(arguments['clf'])
			train_index = arguments['train_index']
			test_index = arguments['test_index']

			x_train, x_test = self.feature_set[train_index], self.feature_set[test_index]
			y_train, y_test = self.labels[train_index], self.labels[test_index]

			clf.fit(x_train, y_train)
			prediction = clf.predict(x_test)

			tn, fp, fn, tp = confusion_matrix(y_test, prediction).ravel()

			self.mutex.acquire()
			try:
				self.tn_lst.append(tn)
				self.fp_lst.append(fp)
				self.fn_lst.append(fn)
				self.tp_lst.append(tp)
			finally:
				self.mutex.release()

			self.queue.task_done()

	def _cross_val_score(self, clf, algorithm):
		kf = KFold(n_splits=self.splits, shuffle=True)

		self.tn_lst = []
		self.fp_lst = []
		self.fn_lst = []
		self.tp_lst = []

		self.mutex = Lock()
		self.queue = queue.Queue()

		threads = []
		for i in range(self.max_thread_count):
			t = Thread(target=self._cross_val_score_queue)
			t.start()
			threads.append(t)

		for train_index, test_index in kf.split(self.feature_set):
			item = {'clf': clf, 'train_index': train_index, 'test_index': test_index}
			self.queue.put(item)

		# Wait until all tasks are finished
		self.queue.join()

		# Stop threads
		for i in range(self.max_thread_count):
			self.queue.put(None)
		for t in threads:
			t.join()

		tn = mean(self.tn_lst)
		fp = mean(self.fp_lst)
		fn = mean(self.fn_lst)
		tp = mean(self.tp_lst)

		recall = tp / (tp + fn)
		precision =  tp / (tp + fp)
		f1_score = 2 * (precision * recall) / (precision + recall)

		with open(self.save_file, 'a') as f:
			f.write('\n')
			f.write('Algorithm: {}\n'.format(algorithm))
			if self.feature_selection == True:
				f.write('Feature Selection Applied\n')
			f.write('K-Folds: {}\n'.format(self.splits))
			f.write('Total Samples: {}\n'.format(self.labels.size))
			f.write('Total Malicious Samples: {}\n'.format(np.count_nonzero(self.labels == 1)))
			f.write('Total Benign Samples: {}\n'.format(np.count_nonzero(self.labels == 0)))
			f.write('Total Features: {}\n'.format(np.size(self.feature_set, 1)))
			f.write('True Positive: {}\n'.format(tp))
			f.write('False Positive: {}\n'.format(fp))
			f.write('True Negative: {}\n'.format(tn))
			f.write('False Negative: {}\n'.format(fn))
			f.write('Recall: {}\n'.format(recall))
			f.write('Precision: {}\n'.format(precision))
			f.write('F1 Score: {}\n'.format(f1_score))
			f.write('\n')


	def svm(self):
		from sklearn import svm

		clf = svm.SVC()
		self._cross_val_score(clf, 'SVM')

	def naive_bayes(self):
		from sklearn.naive_bayes import GaussianNB

		gnd = GaussianNB()
		self._cross_val_score(gnd, 'Naive Bayes')

	def decision_tree(self):
		from sklearn import tree

		clf = tree.DecisionTreeClassifier()
		self._cross_val_score(clf, 'Decision Tree')

	def random_forest(self):
		from sklearn.ensemble import RandomForestClassifier

		clf = RandomForestClassifier(n_estimators=100)
		self._cross_val_score(clf, 'Random Forest')

	def neural_network(self):
		from sklearn.neural_network import MLPClassifier

		# For small datasets, however, ‘lbfgs’ can converge faster and perform better.
		clf = MLPClassifier(solver='lbfgs', alpha=1e-5, \
							hidden_layer_sizes=(5,2), random_state=1)
		self._cross_val_score(clf, 'Neural Network')

	def stochastic_gradient_descent(self):
		from sklearn.linear_model import SGDClassifier
		clf = SGDClassifier(max_iter=1000, tol=1e-3)
		self._cross_val_score(clf, 'Stochastic Gradient Descent Classifier')

	def knn(self):
		from sklearn.neighbors import KNeighborsClassifier
		clf = KNeighborsClassifier(weights='distance')
		self._cross_val_score(clf, 'K-Nearest Neighbors')


def ml(show_pb=False, pickle_dir='./pickle'):
	save_file = './results/results_rules_features.txt'
	if not os.path.exists('./results/'):
		os.makedirs('./results/')
	with open(save_file, 'a') as f:
		f.write('\n-------------------------------------------------------------------------\n')

	# Non-Feature Reduction
	ml = MachineLearning(show_progress_bar=show_pb, save_file=save_file)
	ml.setup(benign_directory='./benign_samples', malicious_directory='./malicious_samples', file_name='rules.json')
	#ml.setup(benign_directory='/tmp/1', malicious_directory='/tmp/2', file_name='rules.json')

	ml.pickle_it(pickle_dir, 'ml_rules__feature_selection_{}'.format(False))

	ml.decision_tree()
	ml.random_forest()
	ml.neural_network()
	ml.naive_bayes()
	ml.stochastic_gradient_descent()
	ml.knn()
	ml.svm()

	# Feature Reduction
	ml.feature_selection_do()
	ml.pickle_it(pickle_dir, 'ml_rules__feature_selection_{}'.format(True))

	ml.decision_tree()
	ml.random_forest()
	ml.neural_network()
	ml.naive_bayes()
	ml.stochastic_gradient_descent()
	ml.knn()
	ml.svm()

def main():
	show_progress_bar = True
	pickle_dir = './pickle'
	ml(show_progress_bar, pickle_dir)


if __name__ == '__main__':
    main()