import argparse
import os
import io
import sys
import progressbar
from threading import Thread, Lock
import pandas
import subprocess
import json
import queue

class feature_setup:
	def __init__(self, tmp_dir='./.tmp/'):
		'''
		'''
		# Generate temporary directory
		self.tmp_dir = tmp_dir
		if not os.path.exists(self.tmp_dir):
			os.makedirs(self.tmp_dir)
		self.tmp_dir = os.path.abspath(self.tmp_dir) + '/'
		self.queue = queue.Queue()
		self.max_thread_count = 8

	def _queued_find_features(self):
		while True:
			arguments = self.queue.get()
			if arguments is None:
				break
			file = arguments['file']
			u_id = arguments['u_id']
			self._find_features(file, u_id)
			self.queue.task_done()


	def _find_features(self, file: str, u_id: int):
		'''
		Find the feature dictionary of the specified file

		Supports multi-threading. Locks when adding features_dict to
		feature_dictionaries list.

		Uses self.mutex to lock resource.

		Args:
			file (str): File to parse and find the feature dictionary for
			u_id (str): Unique id to save a temporary json file to

		Returns:
			Nothing. Appends features to feature_dictionaries list.
		'''
		# Make directory to contain samples
		sample_dir = self.tmp_dir + str(u_id) + '/'
		if not os.path.exists(sample_dir):
			os.makedirs(sample_dir)


		# Run parser
		token_file_name = sample_dir + 'tokens.json'
		rule_file_name = sample_dir + 'rules.json'
		rule_order_file_name = sample_dir + 'rule_order.json'
		# Run node process
		subprocess.run(['node', 'JavaScript/antlr.js', file, 
			token_file_name, 
			rule_file_name,
			rule_order_file_name])

	def find_all_features(self, directory, file_extensions=['.js']):
		# Get file paths
		file_paths = []
		for root, dirs, files in os.walk(directory):
			for file in files:
				for file_extension in file_extensions:
					if file.endswith(file_extension):
						file_paths.append(os.path.join(root, file))

		threads = []
		for i in range(self.max_thread_count):
			t = Thread(target=self._queued_find_features)
			t.start()
			threads.append(t)

		# For each file
		for index, file in enumerate(file_paths):
			# Thread argument
			item = {'file': file, 'u_id': index}
			# Add to threading queue
			self.queue.put(item)

		# Wait until all tasks are finished
		self.queue.join()

		# Stop threads
		for i in range(self.max_thread_count):
			self.queue.put(None)
		for t in threads:
			t.join()

if __name__ == '__main__':
	fs = feature_setup('./benign_samples')
	fs.find_all_features('/home/drc/Desktop/Research/javascript_web_crawler/scripts')